{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alishafique3/Efficient-Machine-Learning_Optimizations-and-Benchmarking/blob/main/Fire_Classification_Part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vSc5cOrNzl0"
      },
      "source": [
        "#Fire and Smoke Detection Using CNN\n",
        "This project is developed using Blog at Pyimagesearch https://www.pyimagesearch.com/2019/11/18/fire-and-smoke-detection-with-keras-and-deep-learning/\n",
        "by Adrian Rosebrock on November 18, 2019\n",
        "\n",
        "It has been modified and updated by me at 28-March-2020\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBCjN0snDtJE"
      },
      "source": [
        "#pip uninstall tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhSm02ZEHDkl"
      },
      "source": [
        "#pip install tensorflow==2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZsLrUgeloXAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Nu0jPKHRoYB2",
        "outputId": "9ee4cec0-215a-4ba1-b6d5-b9ef2aa9d28c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coUz3zU8Orxd"
      },
      "source": [
        "##Import Libraries and Neural Network Model Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDzxiKp_HTx2",
        "outputId": "bdbc8f53-a776-433a-a9e6-9aa53af2f9bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n",
            "/device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-Rl53NyHkM8"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import SeparableConv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class FireDetectionNet:\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes):\n",
        "\t\t# initialize the model along with the input shape to be\n",
        "\t\t# \"channels last\" and the channels dimension itself\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        "\n",
        "\t\t# CONV => RELU => POOL\n",
        "\t\tmodel.add(SeparableConv2D(16, (7, 7), padding=\"same\",\n",
        "\t\t\tinput_shape=inputShape))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t\t# CONV => RELU => POOL\n",
        "\t\tmodel.add(SeparableConv2D(32, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t\t# (CONV => RELU) * 2 => POOL\n",
        "\t\tmodel.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t\t# first set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(128))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization())\n",
        "\t\tmodel.add(Dropout(0.5))\n",
        "\n",
        "\t\t# second set of FC => RELU layers\n",
        "\t\tmodel.add(Dense(128))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization())\n",
        "\t\tmodel.add(Dropout(0.5))\n",
        "\n",
        "\t\t# softmax classifier\n",
        "\t\tmodel.add(Dense(classes))\n",
        "\t\tmodel.add(Activation(\"softmax\"))\n",
        "\n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyB-N0TYOxQg"
      },
      "source": [
        "##Import Data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW_geQAfLc2l"
      },
      "source": [
        "\n",
        "# initialize the path to the fire and non-fire dataset directories\n",
        "FIRE_PATH = '/content/drive/My Drive/Colab Notebooks/Robbery_Accident_Fire_Database2/Fire'\n",
        "NON_FIRE_PATH = '/content/drive/My Drive/Colab Notebooks/spatial_envelope_256x256_static_8outdoorcategories'\n",
        "\n",
        "# initialize the class labels in the dataset\n",
        "CLASSES = [\"Non-Fire\", \"Fire\"]\n",
        "\n",
        "# define the size of the training and testing split\n",
        "TRAIN_SPLIT = 0.75\n",
        "TEST_SPLIT = 0.25\n",
        "\n",
        "# define the initial learning rate, batch size, and number of epochs\n",
        "INIT_LR = 1e-2\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "# set the path to the serialized model after training\n",
        "####MODEL_PATH = os.path.sep.join([\"output\", \"fire_detection.model\"])\n",
        "\n",
        "# define the path to the output learning rate finder plot and\n",
        "# training history plot\n",
        "####LRFIND_PLOT_PATH = os.path.sep.join([\"output\", \"lrfind_plot.png\"])\n",
        "####TRAINING_PLOT_PATH = os.path.sep.join([\"output\", \"training_plot.png\"])\n",
        "\n",
        "# define the path to the output directory that will store our final\n",
        "# output with labels/annotations along with the number of iamges to\n",
        "# sample\n",
        "####OUTPUT_IMAGE_PATH = os.path.sep.join([\"output\", \"examples\"])\n",
        "SAMPLE_SIZE = 50"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knm4-j93Qo01",
        "outputId": "e1fb9a3d-94dc-4c52-8b1e-cb7aca1960dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import sys\n",
        "\n",
        "def load_dataset(datasetPath):\n",
        "\t# grab the paths to all images in our dataset directory, then\n",
        "\t# initialize our lists of images\n",
        "\timagePaths = list(paths.list_images(datasetPath))\n",
        "\tdata = []\n",
        "\n",
        "\t# loop over the image paths\n",
        "\tfor imagePath in imagePaths:\n",
        "\t\t# load the image and resize it to be a fixed 128x128 pixels,\n",
        "\t\t# ignoring aspect ratio\n",
        "\t\timage = cv2.imread(imagePath)\n",
        "\t\timage = cv2.resize(image, (128, 128))\n",
        "\n",
        "\t\t# add the image to the data lists\n",
        "\t\tdata.append(image)\n",
        "\n",
        "\t# return the data list as a NumPy array\n",
        "\treturn np.array(data, dtype=\"float32\")\n",
        "\n",
        "# construct the argument parser and parse the arguments\n",
        "#ap = argparse.ArgumentParser()\n",
        "#ap.add_argument(\"-f\", \"--lr-find\", type=int, default=0,\n",
        "#\thelp=\"whether or not to find optimal learning rate\")\n",
        "#args = vars(ap.parse_args())\n",
        "\n",
        "# load the fire and non-fire images\n",
        "print(\"[INFO] loading data...\")\n",
        "fireData = load_dataset( FIRE_PATH)\n",
        "nonFireData = load_dataset( NON_FIRE_PATH)\n",
        "print(\"[INFO] Completed\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading data...\n",
            "[INFO] Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByGT9vhzPICG"
      },
      "source": [
        "##Preprocessing and Exploring Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogcB2uG9Mh3z",
        "outputId": "f733796a-7bd3-4f03-93c0-8b581872443f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(fireData.shape)\n",
        "print(nonFireData.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1315, 128, 128, 3)\n",
            "(2693, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2EdK6skMvpv"
      },
      "source": [
        "# construct the class labels for the data\n",
        "fireLabels = np.ones((fireData.shape[0],))\n",
        "nonFireLabels = np.zeros((nonFireData.shape[0],))\n",
        "# stack the fire data with the non-fire data, then scale the data\n",
        "# to the range [0, 1]\n",
        "data = np.vstack([fireData, nonFireData])\n",
        "labels = np.hstack([fireLabels, nonFireLabels])\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOxdoAt2SQw-"
      },
      "source": [
        "data /= 255\n",
        "# perform one-hot encoding on the labels and account for skew in the\n",
        "# labeled data\n",
        "labels = to_categorical(labels, num_classes=2)\n",
        "classTotals = labels.sum(axis=0)\n",
        "classWeight = classTotals.max() / classTotals"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classWeight"
      ],
      "metadata": {
        "id": "1AXv2efzsEp1",
        "outputId": "8115622e-484a-4868-a741-1b7e9da17527",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.       , 2.0479088], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84B_vvEQNu50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "698056fb-335e-467c-dce9-e4dc3624954d"
      },
      "source": [
        "print(data.shape)\n",
        "print(labels.shape)\n",
        "print(labels[1:])\n",
        "print(classTotals)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4008, 128, 128, 3)\n",
            "(4008, 2)\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "[2693. 1315.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxGfxhyLE2x_"
      },
      "source": [
        "# construct the training and testing split\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size= TEST_SPLIT, random_state=42)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfKDSuNSOTZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34fd42a1-b925-46fc-defa-5336c991af3a"
      },
      "source": [
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "print(testX.shape)\n",
        "print(testY.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3006, 128, 128, 3)\n",
            "(3006, 2)\n",
            "(1002, 128, 128, 3)\n",
            "(1002, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj6PKlhs7-zj"
      },
      "source": [
        "# %matplotlib inline\n",
        "# plt.figure()\n",
        "# plt.imshow(trainX[1])\n",
        "# plt.colorbar()\n",
        "# plt.grid(False)\n",
        "# plt.show()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJo64hW_8wjx"
      },
      "source": [
        "# plt.figure(figsize=(10,10))\n",
        "# for i in range(25):\n",
        "#     plt.subplot(5,5,i+1)\n",
        "#     plt.xticks([])\n",
        "#     plt.yticks([])\n",
        "#     plt.grid(False)\n",
        "#     plt.imshow(trainX[i], cmap=plt.cm.binary)\n",
        "#     if trainY[i][0] == 1:\n",
        "#       plt.xlabel(\"Non-Fire\")\n",
        "#     else:\n",
        "#       plt.xlabel(\"Fire\")\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlUEZASrPUXZ"
      },
      "source": [
        "##Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpdZbbeuEwdl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892d38f4-a97b-480d-c39f-f9462dfc1cf0"
      },
      "source": [
        "# initialize the training data augmentation object\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=10,\n",
        "\tzoom_range=0.1,\n",
        "\t#width_shift_range=0.2,\n",
        "\t#height_shift_range=0.2,\n",
        "\t#shear_range=0.15,\n",
        "\thorizontal_flip=True)#,\n",
        "\t#fill_mode=\"nearest\")\n",
        "\n",
        "# initialize the optimizer and model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = 'adam'\n",
        "#SGD(lr= INIT_LR, momentum=0.9,\n",
        "#\tdecay= INIT_LR /  NUM_EPOCHS)\n",
        "model = FireDetectionNet.build(width=128, height=128, depth=3,\n",
        "\tclasses=2)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# check to see if we are attempting to find an optimal learning rate\n",
        "# before training for the full number of epochs\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] compiling model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuEo-IWY8E-a",
        "outputId": "491e37a6-00c0-4fbb-b100-a77548bf88f7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " separable_conv2d (Separable  (None, 128, 128, 16)     211       \n",
            " Conv2D)                                                         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 128, 128, 16)      0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128, 128, 16)     64        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 64, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " separable_conv2d_1 (Separab  (None, 64, 64, 32)       688       \n",
            " leConv2D)                                                       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 64, 64, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " separable_conv2d_2 (Separab  (None, 32, 32, 64)       2400      \n",
            " leConv2D)                                                       \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " separable_conv2d_3 (Separab  (None, 32, 32, 64)       4736      \n",
            " leConv2D)                                                       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               2097280   \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,123,813\n",
            "Trainable params: 2,122,949\n",
            "Non-trainable params: 864\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classWeight"
      ],
      "metadata": {
        "id": "QwcE80LExkRx",
        "outputId": "6a56a546-f109-4480-b44b-e8ca1b000406",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.       , 2.0479088], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_weight1 = {1: 1.,\n",
        "                0: 2.04}"
      ],
      "metadata": {
        "id": "Po69P1BSx4AZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(\n",
        "\t#aug.flow(trainX, trainY, batch_size= BATCH_SIZE),\n",
        "  trainX, trainY, batch_size= BATCH_SIZE,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=trainX.shape[0] //  BATCH_SIZE,\n",
        "\tepochs= NUM_EPOCHS,\n",
        "\tclass_weight= class_weight1 ,\n",
        "\tverbose=1)\n",
        "\n",
        "# evaluate the network and show a classification report\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size= BATCH_SIZE)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names= CLASSES))\n",
        "\n",
        "# serialize the model to disk\n",
        "#print(\"[INFO] serializing network to '{}'...\".format( MODEL_PATH))\n",
        "#model.save( MODEL_PATH)"
      ],
      "metadata": {
        "id": "kcyAOfO6pL94",
        "outputId": "5efdfb74-caae-4bfa-a4e6-41ca968c1c79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training network...\n",
            "Epoch 1/50\n",
            "46/46 [==============================] - 19s 61ms/step - loss: 1.1014 - accuracy: 0.7466 - val_loss: 0.6741 - val_accuracy: 0.6507\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 2s 40ms/step - loss: 0.6833 - accuracy: 0.8518 - val_loss: 0.8452 - val_accuracy: 0.6507\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 2s 39ms/step - loss: 0.5206 - accuracy: 0.8783 - val_loss: 1.0791 - val_accuracy: 0.6507\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.3758 - accuracy: 0.9024 - val_loss: 1.4845 - val_accuracy: 0.6507\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 2s 42ms/step - loss: 0.2879 - accuracy: 0.9256 - val_loss: 1.8490 - val_accuracy: 0.6507\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 2s 43ms/step - loss: 0.2314 - accuracy: 0.9381 - val_loss: 2.2161 - val_accuracy: 0.6507\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 2s 40ms/step - loss: 0.2117 - accuracy: 0.9432 - val_loss: 2.4268 - val_accuracy: 0.6507\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.2085 - accuracy: 0.9446 - val_loss: 2.3456 - val_accuracy: 0.6507\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.1437 - accuracy: 0.9630 - val_loss: 2.2292 - val_accuracy: 0.6507\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 2s 40ms/step - loss: 0.1176 - accuracy: 0.9667 - val_loss: 2.3717 - val_accuracy: 0.6507\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 2s 40ms/step - loss: 0.1230 - accuracy: 0.9677 - val_loss: 2.1565 - val_accuracy: 0.6507\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 2s 40ms/step - loss: 0.0796 - accuracy: 0.9806 - val_loss: 2.0136 - val_accuracy: 0.6537\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 2s 42ms/step - loss: 0.0572 - accuracy: 0.9871 - val_loss: 1.5498 - val_accuracy: 0.6677\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 2s 39ms/step - loss: 0.0829 - accuracy: 0.9755 - val_loss: 1.5853 - val_accuracy: 0.6756\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 2s 40ms/step - loss: 0.0607 - accuracy: 0.9840 - val_loss: 0.7657 - val_accuracy: 0.8044\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0421 - accuracy: 0.9905 - val_loss: 0.9691 - val_accuracy: 0.7764\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0478 - accuracy: 0.9871 - val_loss: 0.6509 - val_accuracy: 0.8473\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 2s 40ms/step - loss: 0.0320 - accuracy: 0.9922 - val_loss: 0.6708 - val_accuracy: 0.8523\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 2s 39ms/step - loss: 0.0428 - accuracy: 0.9895 - val_loss: 0.4982 - val_accuracy: 0.8862\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 2s 42ms/step - loss: 0.0625 - accuracy: 0.9833 - val_loss: 0.2941 - val_accuracy: 0.9271\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 2s 43ms/step - loss: 0.0293 - accuracy: 0.9929 - val_loss: 0.3656 - val_accuracy: 0.9112\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0423 - accuracy: 0.9901 - val_loss: 0.4270 - val_accuracy: 0.8982\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 2s 40ms/step - loss: 0.0484 - accuracy: 0.9844 - val_loss: 0.4239 - val_accuracy: 0.9142\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 2s 39ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.6423 - val_accuracy: 0.8713\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0176 - accuracy: 0.9976 - val_loss: 0.6721 - val_accuracy: 0.8613\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 2s 40ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.2912 - val_accuracy: 0.9281\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 2s 41ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.3349 - val_accuracy: 0.9192\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 2s 43ms/step - loss: 0.0189 - accuracy: 0.9963 - val_loss: 0.5222 - val_accuracy: 0.8932\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 2s 40ms/step - loss: 0.0261 - accuracy: 0.9939 - val_loss: 0.3555 - val_accuracy: 0.9232\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0273 - accuracy: 0.9918 - val_loss: 0.3897 - val_accuracy: 0.9202\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 2s 40ms/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.3794 - val_accuracy: 0.9182\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 0.4003 - val_accuracy: 0.9132\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.4464 - val_accuracy: 0.9042\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 2s 41ms/step - loss: 0.0379 - accuracy: 0.9898 - val_loss: 0.4794 - val_accuracy: 0.8862\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 2s 42ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.3309 - val_accuracy: 0.9172\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 2s 40ms/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 0.8827 - val_accuracy: 0.8343\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0418 - accuracy: 0.9884 - val_loss: 0.5271 - val_accuracy: 0.8962\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 2s 40ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.4539 - val_accuracy: 0.9082\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0360 - accuracy: 0.9918 - val_loss: 0.3654 - val_accuracy: 0.9172\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0488 - accuracy: 0.9888 - val_loss: 0.5939 - val_accuracy: 0.8872\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0686 - accuracy: 0.9844 - val_loss: 0.6258 - val_accuracy: 0.8842\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 2s 41ms/step - loss: 0.0522 - accuracy: 0.9871 - val_loss: 0.6852 - val_accuracy: 0.8633\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 2s 42ms/step - loss: 0.0245 - accuracy: 0.9929 - val_loss: 0.5599 - val_accuracy: 0.8982\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.4826 - val_accuracy: 0.8952\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 2s 40ms/step - loss: 0.0168 - accuracy: 0.9973 - val_loss: 0.4555 - val_accuracy: 0.9062\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.3651 - val_accuracy: 0.9222\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.5368 - val_accuracy: 0.8952\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0149 - accuracy: 0.9966 - val_loss: 0.9932 - val_accuracy: 0.8443\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 2s 39ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.3833 - val_accuracy: 0.9232\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 2s 43ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.4525 - val_accuracy: 0.9072\n",
            "[INFO] evaluating network...\n",
            "16/16 [==============================] - 1s 17ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Non-Fire       0.90      0.96      0.93       652\n",
            "        Fire       0.92      0.80      0.86       350\n",
            "\n",
            "    accuracy                           0.91      1002\n",
            "   macro avg       0.91      0.88      0.89      1002\n",
            "weighted avg       0.91      0.91      0.91      1002\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbZUGTJYshjL"
      },
      "source": [
        "# %matplotlib inline\n",
        "# #import matplotlib.pyplot as plt\n",
        "# #print(H.history[\"loss\"])\n",
        "# #N = np.arange(0,  NUM_EPOCHS)\n",
        "# #print(N)\n",
        "# #plt.plot(N,H.history[\"loss\"])\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# N = np.arange(0,  NUM_EPOCHS)\n",
        "# plt.style.use(\"ggplot\")\n",
        "# fig = plt.figure()\n",
        "# plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
        "# plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "# plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
        "# plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "# plt.title(\"Training Loss and Accuracy\")\n",
        "# plt.xlabel(\"Epoch #\")\n",
        "# plt.ylabel(\"Loss/Accuracy\")\n",
        "# plt.legend(loc=\"lower left\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzke-nFaWmNf"
      },
      "source": [
        "# fig.savefig('my_figure.png')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETz4A0HiPcQK"
      },
      "source": [
        "##Exploring Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhXfHHHfFdAV"
      },
      "source": [
        "# print(predictions.shape)\n",
        "# print(predictions[:1])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfPtsYECF9DW"
      },
      "source": [
        "# plt.figure(figsize=(10,10))\n",
        "# for i in range(25):\n",
        "#     plt.subplot(5,5,i+1)\n",
        "#     plt.xticks([])\n",
        "#     plt.yticks([])\n",
        "#     plt.grid(False)\n",
        "#     plt.imshow(testX[i], cmap=plt.cm.binary)\n",
        "#     if testY[i][0] == 1:\n",
        "#       if predictions[i][0] > 0.5:\n",
        "#         plt.xlabel(\"Non-Fire\", color='green')\n",
        "#       else:\n",
        "#         plt.xlabel(\"Non-Fire\", color='red')\n",
        "#     else:\n",
        "#       if predictions[i][1] > 0.5:\n",
        "#         plt.xlabel(\"Fire\", color='green')\n",
        "#       else:\n",
        "#         plt.xlabel(\"Fire\", color='red')\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-FOewTXXkyN"
      },
      "source": [
        "#MODEL_PATH = '/content/drive/My Drive/Colab Notebooks'\n",
        "#model.save( MODEL_PATH)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1yxALt4Zjs_"
      },
      "source": [
        "#model.summary()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import os\n"
      ],
      "metadata": {
        "id": "5tu0cH3tT6-J"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSsHqhvxGxEm"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter1 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "#converter1.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "baseline_tflite_model = converter1.convert()\n",
        "\n",
        "_, baseline_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(baseline_tflite_file, 'wb') as f:\n",
        "  f.write(baseline_tflite_model)\n",
        "\n",
        "print('Saved baseline TFLite model to:', baseline_tflite_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9j0XurLTHXF",
        "outputId": "360b5965-3a67-4e89-8331-7999c1b4cc26"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved baseline TFLite model to: /tmp/tmp5sp4j0wq.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter2 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_tflite_model = converter2.convert()\n",
        "\n",
        "_, quantized_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(quantized_tflite_file, 'wb') as f:\n",
        "  f.write(quantized_tflite_model)\n",
        "\n",
        "print('Saved dyanmic range quantization TFLite model to:', quantized_tflite_file)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l14MGIZoS11G",
        "outputId": "35f0a36a-861c-4ede-b083-82c4853b5604"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved dyanmic range quantization TFLite model to: /tmp/tmpazpt5oem.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter3 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter3.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter3.target_spec.supported_types = [tf.float16]\n",
        "fquantized_tflite_model = converter3.convert()\n",
        "\n",
        "_, fquantized_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(fquantized_tflite_file, 'wb') as f:\n",
        "  f.write(fquantized_tflite_model)\n",
        "\n",
        "print('Saved float16 quantization TFLite model to:', fquantized_tflite_file)"
      ],
      "metadata": {
        "id": "Dlnd47SBWDVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a237664-af62-419a-9dbb-70e964f7cf06"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved float16 quantization TFLite model to: /tmp/tmpsx3nj9ll.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(baseline_tflite_file)))\n",
        "print(\"Size of gzipped dynamic quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_tflite_file)))\n",
        "print(\"Size of gzipped Float16 quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(fquantized_tflite_file)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoK24nZVCxpO",
        "outputId": "724e2d68-7963-401b-bc81-365ba556a80a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of gzipped baseline Keras model: 7885613.00 bytes\n",
            "Size of gzipped dynamic quantized TFlite model: 1642900.00 bytes\n",
            "Size of gzipped Float16 quantized TFlite model: 3919407.00 bytes\n"
          ]
        }
      ]
    }
  ]
}